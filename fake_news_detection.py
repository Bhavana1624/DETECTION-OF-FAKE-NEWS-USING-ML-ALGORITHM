# -*- coding: utf-8 -*-
"""fake news detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/128oVA_z0KfXK9HRY_og9s6JmFJRDeKTx
"""

import numpy as np
import pandas as pd
import nltk

import nltk
nltk.download('punkt')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS
import nltk
import re
from nltk.corpus import stopwords
import seaborn as sns
import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS

import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

fake_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Fake.csv')
print("fake_data",fake_data.shape)

true_data= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/True.csv')
print("true_data",true_data.shape)

fake_data.head(5)

true_data.head(5)

true_data['target'] = 1
fake_data['target'] = 0
df = pd.concat([true_data, fake_data]).reset_index(drop = True)
df['original'] = df['title'] + ' ' + df['text']
df.head()

df.isnull().sum()

nltk.download('stopwords')
stop_words = stopwords.words('english')
stop_words.extend(['from', 'subject', 're', 'edu', 'use'])
def preprocess(text):
    result = []
    for token in gensim.utils.simple_preprocess(text):
        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:
            result.append(token)

    return result

df.subject=df.subject.replace({'politics':'PoliticsNews','politicsNews':'PoliticsNews'})

"""sub_tf_df=df.groupby('target').apply(lambda x:x['title'].count()).reset_index(name='Counts')
sub_tf_df.target.replace({0:'False',1:'True'},inplace=True)
fig = px.bar(sub_tf_df, x="target", y="Counts",color='Counts', barmode='group',height=350)
fig.show()

"""

sub_check=df.groupby('subject').apply(lambda x:x['title'].count()).reset_index(name='Counts')
fig=px.bar(sub_check,x='subject',y='Counts',color='Counts',title='Count of News Articles by Subject')
fig.show()

df['clean_title'] = df['title'].apply(preprocess)
df['clean_title'][0]

df['clean_joined_title']=df['clean_title'].apply(lambda x:" ".join(x))

plt.figure(figsize = (20,20))
wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop_words).generate(" ".join(df[df.target == 1].clean_joined_title))
plt.imshow(wc, interpolation = 'bilinear')

maxlen = -1
for doc in df.clean_joined_title:
    tokens = nltk.word_tokenize(doc)
    if(maxlen<len(tokens)):
        maxlen = len(tokens)
print("The maximum number of words in a title is =", maxlen)
fig = px.histogram(x = [len(nltk.word_tokenize(x)) for x in df.clean_joined_title], nbins = 50)
fig.show()

X_train, X_test, y_train, y_test = train_test_split(df.clean_joined_title, df.target, test_size = 0.2,random_state=2)
vec_train = CountVectorizer().fit(X_train)
X_vec_train = vec_train.transform(X_train)
X_vec_test = vec_train.transform(X_test)

model = LogisticRegression(C=2)

#fit the model
model.fit(X_vec_train, y_train)
predicted_value = model.predict(X_vec_test)

#accuracy & predicted value
accuracy_value = roc_auc_score(y_test, predicted_value)
print(accuracy_value)

cm = confusion_matrix(list(y_test), predicted_value)
plt.figure(figsize = (7, 7))
sns.heatmap(cm, annot = True,fmt='g',cmap='viridis')

df['clean_text'] = df['text'].apply(preprocess)
df['clean_joined_text']=df['clean_text'].apply(lambda x:" ".join(x))

plt.figure(figsize = (20,20))
wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop_words).generate(" ".join(df[df.target == 1].clean_joined_text))
plt.imshow(wc, interpolation = 'bilinear')

maxlen = -1
for doc in df.clean_joined_text:
    tokens = nltk.word_tokenize(doc)
    if(maxlen<len(tokens)):
        maxlen = len(tokens)
print("The maximum number of words in a News Content is =", maxlen)
fig = px.histogram(x = [len(nltk.word_tokenize(x)) for x in df.clean_joined_text], nbins = 50)
fig.show()

X_train, X_test, y_train, y_test = train_test_split(df.clean_joined_text, df.target, test_size = 0.2,random_state=2)
vec_train = CountVectorizer().fit(X_train)
X_vec_train = vec_train.transform(X_train)
X_vec_test = vec_train.transform(X_test)
model = LogisticRegression(C=2.5)
model.fit(X_vec_train, y_train)
predicted_value = model.predict(X_vec_test)
accuracy_value = roc_auc_score(y_test, predicted_value)
print(accuracy_value)

prediction = []
for i in range(len(predicted_value)):
    if predicted_value[i].item() > 0.5:
        prediction.append(1)
    else:
        prediction.append(0)
cm = confusion_matrix(list(y_test), prediction)
plt.figure(figsize = (6, 6))
sns.heatmap(cm, annot = True,fmt='g')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
import re
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier

def load_data():
    data_fake = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Fake.csv')
    data_true = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/True.csv')
    return data_fake, data_true

def preprocess_data(data_fake, data_true):
    data_fake["class"] = 0
    data_true['class'] = 1

    # Remove rows from the end for manual testing
    for i in range(23480, 23470, -1):
        data_fake.drop([i], axis=0, inplace=True)

    for i in range(21416, 21406, -1):
        data_true.drop([i], axis=0, inplace=True)

    data_fake_manual_testing = data_fake.tail(10)
    data_true_manual_testing = data_true.tail(10)

    data_fake_manual_testing['class'] = 0
    data_true_manual_testing['class'] = 1

    data_merge = pd.concat([data_fake, data_true], axis=0)
    data_merge.reset_index(inplace=True)
    data_merge.drop(['index'], axis=1, inplace=True)

    data = data_merge.drop(['title', 'subject', 'date'], axis=1)
    data['text'] = data['text'].apply(wordopt)

    return data

def wordopt(text):
    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub("\\W", " ", text)
    text = re.sub('https?://\S+|www\.|S+', '', text)
    text = re.sub('<."?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

def split_and_vectorize(data):
    x = data['text']
    y = data['class']
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)

    vectorization = TfidfVectorizer()
    xv_train = vectorization.fit_transform(x_train)
    xv_test = vectorization.transform(x_test)

    return xv_train, xv_test, y_train, y_test

def train_and_evaluate_models(xv_train, xv_test, y_train, y_test):
    LR = LogisticRegression()
    LR.fit(xv_train, y_train)
    pred_lr = LR.predict(xv_test)
    print("Logistic Regression:")
    print(classification_report(y_test, pred_lr))

    DT = DecisionTreeClassifier()
    DT.fit(xv_train, y_train)
    pred_dt = DT.predict(xv_test)
    print("Decision Tree:")
    print(classification_report(y_test, pred_dt))

    GB = GradientBoostingClassifier(random_state=0)
    GB.fit(xv_train, y_train)
    predit_gb = GB.predict(xv_test)
    print("Gradient Boosting:")
    print(classification_report(y_test, predit_gb))

    RF = RandomForestClassifier(random_state=0)
    RF.fit(xv_train, y_train)
    pred_rf = RF.predict(xv_test)
    print("Random Forest:")
    print(classification_report(y_test, pred_rf))

    return LR, DT, GB, RF

def output_label(n):
    if n == 0:
        return "Fake News"
    elif n == 1:
        return "Not A Fake News"

def manual_testing(news, vectorization, LR, DT, GB, RF):
    testing_news = {"text": [news]}
    new_def_test = pd.DataFrame(testing_news)
    new_def_test["text"] = new_def_test["text"].apply(wordopt)
    new_x_test = new_def_test["text"]
    new_xv_test = vectorization.transform(new_x_test)

    pred_LR = LR.predict(new_xv_test)
    pred_DT = DT.predict(new_xv_test)
    predit_GB = GB.predict(new_xv_test)
    pred_RF = RF.predict(new_xv_test)

    print("In\nLR Prediction: {}\nDT Prediction: {}\nGB Prediction: {}\nRF Prediction: {}"
          .format(output_label(pred_LR[0]), output_label(pred_DT[0]), output_label(predit_GB[0]), output_label(pred_RF[0])))

if __name__ == "__main__":
    data_fake, data_true = load_data()
    data = preprocess_data(data_fake, data_true)
    xv_train, xv_test, y_train, y_test = split_and_vectorize(data)
    LR, DT, GB, RF = train_and_evaluate_models(xv_train, xv_test, y_train, y_test)

    news_input = str(input("Enter a news text for manual testing: "))
    manual_testing(news_input, vectorization, LR, DT, GB, RF)